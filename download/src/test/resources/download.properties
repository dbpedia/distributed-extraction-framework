# NOTE: format is not java.util.Properties, but org.dbpedia.extraction.dump.download.DownloadConfig

# Default download server. It lists mirrors which may be faster. 
base-url=http://dumps.wikimedia.org/

# Replace by your target folder.
base-dir=/home/gonephishing/dbpedia-extraction/distributed-extraction-framework/dumps/f1/

# This setting is recommended for large languages that have part files (eg. en, fr). See below. Replace xx/yy by your language.
#download=xx,yy:@pages-articles\d+\.xml.*\.bz2
download=en:pages-articles1.xml-p000000010p000010000.bz2

# This setting should be provided for small languages that have no part files (eg. li)
#download=xx,yy:pages-articles.xml.bz2

# You may provide multiple "download=" lines for different types of languages, just like above.

###### Download part files ######
#
# Please make sure that the regex actually matches the format used for xx dumps
# by checking http://dumps.wikimedia.org/xxwiki/yyyymmdd
#
# Example:
# enwiki => enwiki-20131120-pages-articles1.xml-p000000010p000010000.bz2 hence @pages-articles\d+\.xml-p\d+p\d+\.bz2 matches
# frwiki => frwiki-20131120-pages-articles1.xml.bz2 hence @pages-articles\d+\.xml\.bz2 matches (the previous regex does not!)
#
# NOTE: @pages-articles\d+\.xml.*\.bz2 is especially recommended when using the distributed downloader because it captures both
# the above types and exploits maximum parallelism by allowing multiple part files to be downloaded and processed simultaneously.
#
# Remember that certain languages have small dumps and therefore no part files at all. They need to be handled with only
# pages-articles.xml.bz2. Example with both small and large languages (setting download multiple times works like appending; so
# adding both download's below is perfectly valid):
#
# download=en,fr:@pages-articles\d+\.xml.*\.bz2
# download=li,bn,ilo:pages-articles.xml.bz2
#
# commonswiki => it does not have part files! This is true for other wikis as well. In this case xx:pages-articles.xml.bz2
# shoud be used (e.g. commons:pages-articles.xml.bz2 or cowiki:pages-articles.xml.bz2)
#
# download=xx:@pages-articles\d+\.xml-p\d+p\d+\.bz2
# download=xx:@pages-articles\d+\.xml.*\.bz2

# Only needed for the ImageExtractor
# download=commons:pages-articles.xml.bz2

# Unzip files while downloading? Not necessary, extraction will unzip on the fly. Let's save space.
unzip=false

# Sometimes connecting to the server fails, so we try five times with pauses of 10 seconds.
retry-max=5
retry-millis=1000
